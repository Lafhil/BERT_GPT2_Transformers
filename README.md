# üß† BERT News Classifier - AG News

Ce projet impl√©mente un mod√®le de classification de texte bas√© sur **BERT** pour cat√©goriser des articles d‚Äôactualit√© en quatre classes : `World`, `Sports`, `Business` et `Sci/Tech`. Il utilise le dataset **AG News**.

## üìÇ Structure du projet

```
bert_news_classifier/
‚îÇ
‚îú‚îÄ‚îÄ BERT_code.py          # Script d'entra√Ænement et de test du mod√®le
‚îú‚îÄ‚îÄ BERT_test.py          # Script de test du mod√®le sauvegard√©
‚îú‚îÄ‚îÄ BERT_model/            # Dossier contenant le mod√®le entra√Æn√© et le tokenizer
‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_config.json
‚îÇ   ‚îú‚îÄ‚îÄ vocab.txt
‚îÇ   ‚îî‚îÄ‚îÄ special_tokens_map.json
‚îú‚îÄ‚îÄ optimizer.pt           # √âtat de l'optimiseur sauvegard√©
‚îú‚îÄ‚îÄ epoch.txt              # Derni√®re √©poque sauvegard√©e
‚îú‚îÄ‚îÄ README.md              # Fichier de documentation
‚îî‚îÄ‚îÄ requirements.txt       # Biblioth√®ques n√©cessaires (√† cr√©er)
```

## üõ†Ô∏è Installation

1. Cloner ce d√©p√¥t ou copier les fichiers dans un dossier.
2. Installer les biblioth√®ques n√©cessaires :

```bash
pip install transformers datasets torch tqdm
```

## üì¶ Donn√©es utilis√©es

Le dataset [AG News](https://huggingface.co/datasets/ag_news) est automatiquement t√©l√©charg√© avec la biblioth√®que `datasets`.

- **Taille** : 120,000 exemples d'entra√Ænement
- **Classes** : `World`, `Sports`, `Business`, `Sci/Tech`

## üß™ Utilisation

### Entra√Ænement

Le script `BERT_model.py` entra√Æne le mod√®le sur 3 √©poques, puis le sauvegarde :

```bash
python BERT_model.py
```

### Test rapide

√Ä la fin du script, plusieurs pr√©dictions sont effectu√©es sur des textes personnalis√©s, avec la classe pr√©dite affich√©e.

```python
Texte : NASA discovered water on Mars.
Classe pr√©dite : Sci/Tech
```

### Recharger le mod√®le sauvegard√©

```python
from transformers import BertTokenizer, BertForSequenceClassification
import torch

model = BertForSequenceClassification.from_pretrained("BERT_model")
tokenizer = BertTokenizer.from_pretrained("BERT_model")
```

## üìà R√©sultats

- **Loss d'entra√Ænement** :
  - √âpoque 1 : 0.2302
  - √âpoque 2 : 0.1517
  - √âpoque 3 : 0.1161
- **Exemples de pr√©dictions correctes** :
  - "The stock market is showing signs of recovery." ‚Üí `Business`
  - "The World Cup 2022 was amazing!" ‚Üí `Sports`
  - "NASA discovered water on Mars." ‚Üí `Sci/Tech`
  - "The United Nations held a meeting..." ‚Üí `World`

## ‚úÖ Fichiers √† inclure

- `BERT_model.py`
- `README.md`
- `BERT_model/` (tout le dossier)
- `optimizer.pt`
- `epoch.txt`
- `requirements.txt` (√† g√©n√©rer via `pip freeze > requirements.txt`)

## ‚ú® Am√©liorations possibles

- √âvaluer le mod√®le sur le test set (accuracy, f1-score‚Ä¶)
- Ajouter une interface graphique ou une API Flask
- Ajouter le support multi-langues

---



Manssour Youssef 
lafhil ouadie  

